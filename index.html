<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Surgan Jandial</title>
  
  <meta name="author" content="Surgan Jandial">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px;">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Surgan Jandial</name>
              </p>
              <p>I am a research associate at Adobe MDSR Labs, Noida, where I work on computer vision and machine learning. Prior to this in 2021, I finished my undergraduate from  <a href="http://iith.ac.in">CS, Indian Institute of Technology, Hyderabad</a>, where I was fortunate to work with <a href="https://people.iith.ac.in/vineethnb/index.html">Prof. Vineeth Balasubramanian</a>. 
              </p>
              <p>
                Lately, I got interested to research on transfering the existing knowledge via <i>Knowledge Distillation, and Transfer Learning (mostly Transferability Estmation)</i>. While prior to that, my urge to AI led me to explore multiple directions: <i>Virtual Try On, Text Based Image Retrieval, Document Analysis, and so on. </i>
              </p>

              <!-- <p style="color: red; font-style: italic;">At <strong>ECCV 2022!</strong> Looking forward to connect, learn or grab a meal. Do reach out.</p> -->
              <p>
                
              </p>
              <p style="text-align:center">
                <a href="mailto:jandialsurgan@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=1sWyXaoAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/surgan-jandial-9a085a14b/">Linkedin</a> &nbsp/&nbsp;
                <a href="https://twitter.com/JandialSurgan">Twitter</a>  
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/icon.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/icon.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Conferences</heading>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					

          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/disundis_eccv2022.png' width="200" height="100" style="margin-top: 12%; margin-left: -8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136730586.pdf">
                <papertitle>Distilling the Undistillable: Learning from a Nasty Teacher</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial</strong>,
              Yash Khasbage,
              <a href="https://arghyapal.github.io/itsarghyapal.github.io/">Arghya Pal</a>,
							<a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>, <br>
              Balaji Krishnamurthy
              <br> <p></p>
              <em>ECCV</em>, 2022
              <br>
              <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
              <p></p>
              <p>

              </p>
            </td>
          </tr>
					
					
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/retro_cods2023.jpg' width="200" height="100"  style="margin-top: 12%; margin-left: -7%;">
              </div>
          
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Retro-KD: Past States for Regularizing Targets in Teacher-Student Learning</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial<sup>*</sup></strong>, 
              Yash Khasbage<sup>*</sup>,
              <a href="https://arghyapal.github.io/itsarghyapal.github.io/">Arghya Pal</a>, Balaji Krishnamurthy, <br>
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>,
              <br> <p></p>
              <em>CODS-COMAD</em>, 2023
              <br>
              <!-- <a href="https://arxiv.org/abs/2201.00392">arXiv</a> -->
              <p></p>
              <!-- <p>
                We propose to regularize teacher-student training leveraging student's past state outputs.
              </p> -->
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/monomer_wacv23.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/pdf/2209.06584.pdf">
                <papertitle>One-Shot Doc Snippet Detection: Powering Search in Document Beyond Text</papertitle>
              </a>
              <br>
              <a href="https://java-abhinav07.github.io">Abhinav Java<sup>*</sup></a>, &#32;
              Shripad Deshmukh<sup>*</sup>, &#32;
              Milan Aggarwal, &#32;
              <strong>Surgan Jandial</strong>, &#32;
              Mausoom Sarkar,&#32; <br> Balaji Krishnamurthy
              <br> <p></p>
              <em>WACV</em>, 2023 
              <br>
							<!-- <a href="https://arxiv.org/abs/2209.06584">arXiv</a> /  -->
              <p></p>
              <!-- <p>We propose.</p> -->
            </td>
          </tr>

			    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one">
			          <img src='images/sac_wacv2022.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
			        </div>
			     
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a href="https://openaccess.thecvf.com/content/WACV2022/html/Jandial_SAC_Semantic_Attention_Composition_for_Text-Conditioned_Image_Retrieval_WACV_2022_paper.html">
			            <papertitle>SAC: Semantic Attention Composition for Text-Conditioned Image Retrieval </papertitle>
			          </a>
			          <br>
			          <strong>Surgan Jandial<sup>*</sup></strong>, &nbsp;
			          <a href="https://pinkeshbadjatiya.github.io">Pinkesh Badjatiya<sup>*</sup></a>, &nbsp;
			          <a href="https://www.pranitchawla.com/home">Pranit Chawla<sup>*</sup></a>, &nbsp;
			          <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>, &nbsp;
			          Mausoom Sarkar, &nbsp; <br> Balaji Krishnamurthy
			          <br> <p></p>
			    <em>WACV</em>, 2022
			          <br> <p></p>
			          <!-- <a href="https://openaccess.thecvf.com/content/WACV2022/html/Jandial_SAC_Semantic_Attention_Composition_for_Text-Conditioned_Image_Retrieval_WACV_2022_paper.html">arXiv</a> -->
			          <p></p>
			          <!-- <p>Explicitly modeling reflections in NeRF produces realistic shiny surfaces and accurate surface normals, and lets you edit materials.</p> -->
			        </td>
			      </tr>
						
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/retrospective_kdd2020.png'  width="200" height="100" style="margin-top: 12%; margin-left: -8%;">
              </div>

            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.13593">
                <papertitle>Retrospective Loss: Looking Back to Improve Training of Deep Neural Networks</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial<sup>*</sup></strong>,
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,
              Mausoom Sarkar,
              Piyush Gupta,
              Balaji Krishnamurthy, <br>
              Vineeth N Balasubramanian
              <br> <p></p>
							<em>KDD</em>, 2020 &nbsp
              <br>
              <!-- <a href="https://arxiv.org/abs/2006.13593">arXiv</a> -->
              <p></p>
              <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
            </td>
          </tr> 

          <tr onmouseout="rawnerf_stop()" onmouseover="rawnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sievenet_wacv2020.png' width="200" height="120" style="margin-top: 9%; margin-left: -8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2001.06265">
                <papertitle>SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial<sup>*</sup></strong>,
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,
              <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>, 
              Mayur Hemani,
              Balaji Krishnamurthy, <br>
              Abhijeet Halwai
              <br> <p></p>
							<em>WACV</em>, 2020 <br>
              <em>Also presented at <a href="https://visual.cs.brown.edu/workshops/aicc2020/">Workshop on AI for Content Creation, CVPR 2020 </a></em>
              <br>
              <!-- <a href="https://arxiv.org/abs/2001.06265">arXiv</a> -->
              <p></p>
              <p>
								Media Coverage: &nbsp;<a href="https://venturebeat.com/ai/adobes-ai-lets-you-preview-any-item-of-clothing-on-a-virtual-body-model/">Venturebeat</a> / <a href="https://beebom.com/adobes-ai-fits-clothes-any-body-type/">Beebom</a> / <a href="https://wwd.com/business-news/technology/adobe-technology-ai-project-clothes-swap-in-experience-manager-1203640752/">WWD</a> </p>
            </td>
          </tr> 
					
            <tr>
            <td style="padding:20px;vertical-align:middle">
              <heading>Workshops</heading>
            </td>
          </tr>
   
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/condition_diffusion_cvpr2022w.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              
              <a href="https://arxiv.org/abs/2205.03859">
                <papertitle>On Conditioning the Input Noise for Controlled Image Generation with Diffusion Models</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial <sup>*</sup></strong>, 
              Vedant Singh<sup>*</sup>,
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra</a>, Siddarth Ramesh, Balaji Krishnamurthy <br>
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>,
              <br> <p></p>
        <em><a href="https://ai4cc.net">Workshop on AI for Content Creation, CVPR 2022 </a> </em>
              <br> <p></p>
              <!-- <a href="https://arxiv.org/abs/2205.03859">arXiv</a> -->
              <p></p>
              <!-- <p>Regularizing unseen views during optimization enables view synthesis from as few as 3 input images.</p> -->
            </td>
          </tr> 


          <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stycon_cvprw21.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/papers/Chawla_Leveraging_Style_and_Content_Features_for_Text_Conditioned_Image_Retrieval_CVPRW_2021_paper.pdf">
                <papertitle>Leveraging Style and Content features for Text Conditioned Image Retrieval</papertitle>
              </a>
              <br>
             <a href="https://www.pranitchawla.com"> Pranit Chawla </a>, <strong>Surgan Jandial</strong>, 
             <a href="http://pinkeshbadjatiya.github.io">Pinkesh Badjatiya</a>, <a href="http://media.mit.edu/people/ayushc/overview/">Ayush Chopra</a>, Mausoom Sarkar <br>
             Balaji Krishnamurthy
              <br> <p></p>
        <em><a href="https://sites.google.com/zalando.de/cvfad2021/home">Workshop on Computer Vision for Fashion, Art and Design, CVPR 2022 </a> </em>
              <br>
              <!-- <a href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/papers/Chawla_Leveraging_Style_and_Content_Features_for_Text_Conditioned_Image_Retrieval_CVPRW_2021_paper.pdf">arXiv</a> -->
              <p></p>
              <!-- <p>We can do city-scale reconstruction by training multiple NeRFs with millions of images.</p> -->
            </td>
          </tr>
					
          <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/advgan.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1908.00706">
                <papertitle>AdvGAN++: Harnessing latent layers for adversary generation</papertitle>
              </a>
              <br>
              <strong>Surgan Jandial<sup>*</sup></strong>,
              <a href="http://puneet2000.github.io">Puneet Mangla<sup>*</sup></a>,
              Sakshi Varshney<sup>*</sup>,
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian </a>
              <br> <p></p>
              <em><a href="https://neuralarchitects.org">Neural Architect Workshop, ICCV 2019 </a></em>
              <br>
              <!-- <a href="https://arxiv.org/abs/1908.00706">arXiv</a> -->
              <p></p>
              <!-- <p>Combining NeRF with pose estimation lets you use a monocular video to do free-viewpoint rendering of a human.</p> -->
            </td>
          </tr>
					
          <tr onmouseout="urf_stop()" onmouseover="urf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mul_warp.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Ayush_Robust_Cloth_Warping_via_Multi-Scale_Patch_Adversarial_Loss_for_Virtual_ICCVW_2019_paper.pdf">
                <papertitle>Robust Cloth Warping via Multi-Scale Patch Adversarial Loss for VirtualTry-On Framework</papertitle>
              </a>
              <br>
							<strong>Surgan Jandial<sup>*</sup></strong>,
              <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>, 
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>, Mayur Hemani, <br>
              Balaji Krishnamurthy
              <br> <p></p>
							<em><a href="https://project.inria.fr/whbu/">Workshop on Human Behaviour Understanding, ICCV 2019</a></em>
              <br>
              <!-- <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Ayush_Robust_Cloth_Warping_via_Multi-Scale_Patch_Adversarial_Loss_for_Virtual_ICCVW_2019_paper.pdf">arXiv</a> -->
              <p></p>
              <!-- <p>
								Incorporating lidar and explicitly modeling the sky lets you reconstruct urban environments.</p> -->
            </td>
          </tr> 

	
  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/aux_seg_ton_iccv19.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
      </div>

    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Ayush_Powering_Virtual_Try-On_via_Auxiliary_Human_Segmentation_Learning_ICCVW_2019_paper.pdf">
        <papertitle>Powering Virtual Try-On via Auxiliary Human Segmentation Learning</papertitle>
      </a>
      <br>
      <strong>Surgan Jandial<sup>*</sup></strong>,
      <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>, 
      <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>, Balaji Krishnamurthy
      <br> <p></p>
			<em> <a href="https://sites.google.com/view/cvcreative">Workshop on Computer Vision for Fashion, Art and Design, ICCV 2019 </a> </em>
      <br> 
      <!-- <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Ayush_Powering_Virtual_Try-On_via_Auxiliary_Human_Segmentation_Learning_ICCVW_2019_paper.pdf">arXiv</a> -->
      <p></p>
      <!-- <p>
      Dense depth completion techniques applied to freely-available sparse stereo data can improve NeRF reconstructions in low-data regimes.
      </p> -->
    </td>
  </tr>
	
  <tr>
    <td style="padding:20px;vertical-align:middle">
      <heading>Patents</heading>
    </td>
  </tr>  
  

        </tbody></table>

        <table>
          <tbody>
            <tr>
              <td>

                <ul>
                <li> A Novel Multimodal One Shot Detection Approach for Document Snippet Search </li>
                <li>SelfDisturb: Novel Semantic Noise based Soft Label Regularization for Distilling Model Knowledge</li>
                <li>AdaData: Novel method to simplify data points for easier understanding of neural networks </li>
                <li>Novel Method and Apparatus to Control Diffusion Model Image Generation</li>
                <li>A Novel Method to improve Teacher-Student models in Model Distillation by Regularizing Targets</li>
                <li> Text-Conditioned Image Search based on Transformation, Aggregation, and Composition of Visio-Linguistic Features</li>
                <li> Text Conditioned Image Search based on Dual-Disentangled Feature Composition</li>
                <li>SieveNet: A Unified Framework for Robust Fashion Apprehension</li>
                <li>Robust Warping via Multi-Scale Patch Adversarial Loss for Virtual Try-on</li>
                <li>Retrospection: An Online Mining Technique for Efficient Training of Deep Neural Networks</li>
              </ul>
              </td>
            </tr>
          </tbody>

        </table>
				
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
            <strong>* </strong> denotes equal contribution
            </td>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 <a href="https://jonbarron.info"> this </a> made my life easy.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
