<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Surgan Jandial</title>
  
  <meta name="author" content="Surgan Jandial">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px;">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Surgan Jandial</name>
              </p>

            <p>I am a first-year <strong>Master's in Robotics (MSR)</strong> student at the <a href="https://www.ri.cmu.edu/"> Carnegie Mellon University (Robotics Institute) </a>.
              
              <br><br>
              Previously, I was a <strong>Research Associate</strong> at MDSR Labs, <a href="https://www.adobe.com/home?acomLocale=in">Adobe</a> where I focused on the key areas of <strong>Computer Vision </strong> (Generative Models - Diffusion/GAN, Distillation, Transfer Learning, Synthetic Data), <strong>Vision-Language </strong> (Retrieval, Style Transfer, Understanding/Leveraging CLIP space), and <strong>Language Models</strong> (LLM Bias, Memorization, Efficient Deployment). </p>

            <p>Even before that, I earned my <strong>Bachelor's in CS</strong> from  <a href="http://iith.ac.in">Indian Institute of Technology (IIT), Hyderabad</a>, where I worked with <a href="https://people.iith.ac.in/vineethnb/index.html">Prof. Vineeth N Balasubramanian</a> on problems related to <strong>Robust</strong> (Adversarial Attacks), and <strong>Efficient Perception </strong>(Efficient Training, Knowledge Distillation).
              </p>
              <p>
              Particularly, my prior research studied the themes of: <br> 
                <ul>
              
              <li>   <strong> Resource-Efficiency for widespread access:</strong>   efficient model training, efficient model selection,  efficient model size, data efficiency via synthetic data. </li>

                <br> 
              
              <li>  <strong> Safety for long-term usage or deployment:</strong>  model fairness, model security. </li>
              <br>
              <li> <strong>Applications for Vision, Vision-Language, and Language. </strong></li>
            </ul>
            </p>

            <p>

           My current interests are broad into <strong>Vision</strong> and <strong>Language</strong> modalities, and am keen to study the upcoming topics with a lens of efficiency, robustness, safety.

            </p>
            <p>
              <strong><u>Update</u></strong>: Open to Summer 2025 internships for Research/Applied Research/AI-ML roles. If you see a fit, please do reach out!

            </p>

              <!-- <p>
                Lately, I got interested to research on transfering the existing knowledge via <i>Knowledge Distillation, and Transfer Learning (mostly Transferability Estmation)</i>. While prior to that, my urge to AI led me to explore multiple directions: <i>Virtual Try On, Text Based Image Retrieval, Document Analysis, and so on. </i>
              </p> -->

              <!-- <p style="color: red; font-style: italic;">At <u><strong>ECCV 2022!</strong></u> Looking forward to connect, learn or grab a meal. Do reach out.</p> -->
              <p>
                
              </p>
              <p style="text-align:center">
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?user=1sWyXaoAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/surgan-jandial-9a085a14b/">Linkedin</a> &nbsp/&nbsp;
                <a href="https://twitter.com/JandialSurgan">Twitter</a> &nbsp/&nbsp; -->
                <a href="mailto:jandialsurgan@gmail.com">Email</a> &nbsp/&nbsp;
                <a href="#patents">List of Patents</a> &nbsp/&nbsp;
                <a href="#preprint">Preprints</a> &nbsp/&nbsp;
                <a href="personal.html"> Some personal interests</a> 

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/icon.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/icon.jpg" class="hoverZoomLink"></a>
              &nbsp&nbsp&nbsp&nbsp
              <a href="https://scholar.google.com/citations?user=1sWyXaoAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
              <a href="https://www.linkedin.com/in/surgan-jandial-9a085a14b/">Linkedin</a> &nbsp/&nbsp;
              <a href="https://twitter.com/JandialSurgan">Twitter</a>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Conferences</heading>
            <div style="display: flex;">
              <div > (* denotes equal contribution) </div>
            </div>

          </td>
        </tr>
      </tbody></table>

      
      <title>Publications Component</title>
<style>
  .container {
    display: flex;
    justify-content: space-between;
    font-family: Arial, sans-serif;
  }

  .column {
    width: 100%; /* Adjust the width as needed */
    margin: 10px;
    background-color: #f2f2f2;
    border: 1px solid #ccc;
    border-radius: 4px;
    padding: 20px;
  }

  .publication {
    background-color: white;
    border: 1px solid #ddd;
    padding: 10px;
    margin-bottom: 10px;
    border-radius: 4px;
  }

  .publication h3 {
    font-size: 18px;
    color: #333;
    margin: 0 0 10px 0;
  }

  .publication p {
    font-size: 14px;
    color: #666;
    margin: 0;
  }

  .badge {
    display: inline-block;
    padding: 2px 8px;
    font-size: 12px;
    color: white;
    background-color: green;
    border-radius: 4px;
    margin-right: 5px;
  }

  .badge.trustworthy {
    background-color: green;
  }
  .badge.issues {
    background-color: indianred;
  }
  .badge.filed {
    background-color: rgba(0, 136, 247, 0.918);
  }

  .badge.filing {
    background-color: rgb(138, 136, 63);
  }


  .badge:last-child {
    margin-right: 0;
  }


  .academic td, th {
    padding: 0; /* Removes padding within cells */
        margin: 0;  /* Removes any margin within cells */
  }

</style>
</head>
<body>

  </div>

</div>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
					

  
          					
          <tr onmouseout="malle_stop()" onmouseover="malle_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cafie.png' width="200" height="100"  style="margin-top: 12%; margin-left: -7%;">
              </div>
          
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2311.05451">
                <papertitle>All Should Be Equal in the Eyes of Language Models: Counterfactually Aware Fair Text Generation</papertitle>
              </a>
              <br>
            Pragyan Banerjee<sup>*</sup>,  &nbsp; 
              Abhinav Java<sup>*</sup>, &nbsp;
              <u><strong> Surgan Jandial<sup>*</sup></strong></u>, &nbsp;
              Simra Shahid <sup>*</sup>, &nbsp;
              Shaz Furniturewala, &nbsp;
              Balaji Krishnamurthy, &nbsp; <a href="http://sumitbhatia.net/">Sumit Bhatia</a>
              <br> <p></p>
              <em>AAAI</em>, 2024 <u><strong></strong></u>
              <br>
              <!-- <a href="https://arxiv.org/abs/2201.00392">arXiv</a> -->
              <p></p>

              <span class="badge trustworthy">Model Fairness</span>
              <span class="badge">Large Language Models</span>
        
              <!-- <p>
                We propose to regularize teacher-student training leveraging student's past state outputs.
              </p> -->
            </td>
          </tr>
					
          <tr onmouseout="malle_stop()" onmouseover="malle_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/retro_cods2023.jpg' width="200" height="100"  style="margin-top: 12%; margin-left: -7%;">
              </div>
          
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3570991.3571014">
                <papertitle>Retro-KD: Past States for Regularizing Targets in Teacher-Student Learning</papertitle>
              </a>
              <br>
              <u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp; Yash Khasbage<sup>*</sup>,  &nbsp;
              <a href="https://arghyapal.github.io/itsarghyapal.github.io/">Arghya Pal</a>,  &nbsp; Balaji Krishnamurthy, <br>
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>
              <br> <p></p>
              <em>CODS-COMAD</em>, 2023 <u><strong><font color="red">(Oral)</font></strong></u>
              <br> <br>
              <span class="badge trustworthy">Knowledge Distillation</span>
              <span class="badge">Model Compression</span>

              <!-- <a href="https://arxiv.org/abs/2201.00392">arXiv</a> -->
              <p></p>
              <!-- <p>
                We propose to regularize teacher-student training leveraging student's past state outputs.
              </p> -->
            </td>
          </tr>
					
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/monomer_wacv23.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/pdf/2209.06584.pdf">
                <papertitle>One-Shot Doc Snippet Detection: Powering Search in Document Beyond Text</papertitle>
              </a>
              <br>
              <a href="https://java-abhinav07.github.io">Abhinav Java<sup>*</sup></a>,  &nbsp;
              Shripad Deshmukh<sup>*</sup>,  &nbsp;
              Milan Aggarwal,  &nbsp;
              <u><strong>Surgan Jandial</strong></u>,  &nbsp;
              Mausoom Sarkar,  &nbsp; Balaji Krishnamurthy
              <br> <p></p>
              <em>WACV</em>, 2023 
              <br> <br>

              <span class="badge trustworthy">Applications</span>
              <span class="badge">Computer Vision</span>

							<!-- <a href="https://arxiv.org/abs/2209.06584">arXiv</a> /  -->
              <p></p>
              <!-- <p>We propose.</p> -->
            </td>
          </tr>
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/disundis_eccv2022.png' width="200" height="100" style="margin-top: 12%; margin-left: -8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136730586.pdf">
                <papertitle>Distilling the Undistillable: Learning from a Nasty Teacher</papertitle>
              </a>
              <br>
              <u><strong>Surgan Jandial</strong></u>,  &nbsp;
              Yash Khasbage,  &nbsp;
              <a href="https://arghyapal.github.io/itsarghyapal.github.io/">Arghya Pal</a>,  &nbsp;
							<a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>,  &nbsp; <br>
              Balaji Krishnamurthy
              <br> <p></p>
              <em>ECCV</em>, 2022
              <br> <br>
              <span class="badge trustworthy">Knowledge Distillation</span>
              <span class="badge">Model Stealing</span>
              <span class="badge">Model Security</span>

              <!-- <a href="https://arxiv.org/abs/2209.14988">arXiv</a> -->
              <p></p>
              <p>

              </p>
            </td>
          </tr>
					
			    <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
			      <td style="padding:20px;width:25%;vertical-align:middle">
			        <div class="one">
			          <img src='images/sac_wacv2022.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
			        </div>
			     
			      </td>
			            <td style="padding:20px;width:75%;vertical-align:middle">
			          <a href="https://openaccess.thecvf.com/content/WACV2022/html/Jandial_SAC_Semantic_Attention_Composition_for_Text-Conditioned_Image_Retrieval_WACV_2022_paper.html">
			            <papertitle>SAC: Semantic Attention Composition for Text-Conditioned Image Retrieval </papertitle>
			          </a>
			          <br>
			          <u><strong>Surgan Jandial<sup>*</sup></strong></u>, &nbsp;
			          <a href="https://pinkeshbadjatiya.github.io">Pinkesh Badjatiya<sup>*</sup></a>, &nbsp;
			          <a href="https://www.pranitchawla.com/home">Pranit Chawla<sup>*</sup></a>, &nbsp;
			          <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>, &nbsp;
			          Mausoom Sarkar, &nbsp;  Balaji Krishnamurthy
			          <br> <p></p>
			    <em>WACV</em>, 2022
			          <br> <p></p>
                <span class="badge trustworthy">Applications</span>
                <span class="badge">Computer Vision</span>
                <span class="badge">Vision Language Models</span>

  
			          <!-- <a href="https://openaccess.thecvf.com/content/WACV2022/html/Jandial_SAC_Semantic_Attention_Composition_for_Text-Conditioned_Image_Retrieval_WACV_2022_paper.html">arXiv</a> -->
			          <p></p>
			          <!-- <p>Explicitly modeling reflections in NeRF produces realistic shiny surfaces and accurate surface normals, and lets you edit materials.</p> -->
			        </td>
			      </tr>
						
      
          
          <tr onmouseout="mip360_stop()" onmouseover="mip360_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/retrospective_kdd2020.png'  width="200" height="100" style="margin-top: 12%; margin-left: -8%;">
              </div>

            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.13593">
                <papertitle>Retrospective Loss: Looking Back to Improve Training of Deep Neural Networks</papertitle>
              </a>
              <br>
              <u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp;
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,  &nbsp;
              Mausoom Sarkar,  &nbsp;
              Piyush Gupta,  &nbsp;
              Balaji Krishnamurthy,  &nbsp;
              Vineeth N Balasubramanian
              <br> <p></p>
							<em>KDD</em>, 2020 &nbsp
              <br> <br>
              <span class="badge trustworthy">Efficient Model Training</span>
              <!-- <span class="badge"></span> -->

            </td>
          </tr> 

          <tr onmouseout="rawnerf_stop()" onmouseover="rawnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sievenet_wacv2020.png' width="200" height="120" style="margin-top: 9%; margin-left: -8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2001.06265">
                <papertitle>SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On</papertitle>
              </a>
              <br>
              <u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp;
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,  &nbsp;
              <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>,  &nbsp;
              Mayur Hemani,  &nbsp;
              Balaji Krishnamurthy,  &nbsp;
              Abhijeet Halwai
              <br> <p></p>
							<em>WACV</em>, 2020 <br>
              <em>Also presented at <a href="https://visual.cs.brown.edu/workshops/aicc2020/">Workshop on AI for Content Creation, CVPR 2020 </a></em>
              <br>
              <!-- <a href="https://arxiv.org/abs/2001.06265">arXiv</a> -->
              <p></p>
              <p>
								Media Coverage: &nbsp;<a href="https://venturebeat.com/ai/adobes-ai-lets-you-preview-any-item-of-clothing-on-a-virtual-body-model/">Venturebeat</a> / <a href="https://beebom.com/adobes-ai-fits-clothes-any-body-type/">Beebom</a> / <a href="https://wwd.com/business-news/technology/adobe-technology-ai-project-clothes-swap-in-experience-manager-1203640752/">WWD</a> </p>
                <span class="badge trustworthy">Applications</span>
                <span class="badge">Computer Vision</span>
  
              </td>
          </tr> 
					
            <tr>

            <td style="padding:20px;width:30%;vertical-align:middle">
              <heading>Workshops</heading> 
              <div style="display: flex;">
                <div > (* denotes equal contribution) </div>
              </div>
  
            </td>
          </tr>
   
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/bird.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              
              <a href="https://openreview.net/pdf?id=sXYJpfoW1V">
                <papertitle>Towards Fair Knowledge Distillation using Student Feedback</papertitle>
              </a>
              <br>
              
              Abhinav Java <sup>*</sup>,  &nbsp;
              <u><strong>Surgan Jandial<sup>*</sup> </strong></u>,  &nbsp; Chirag Agarwal
              <br> <br>
        <em><a href="https://es-fomo.com/">Workshop on Efficient Systems for Foundation Models, ICML 2023</a> <br>
          Under review at a Top-Tier ML Conference
              <br> </em> <p></p> 
              <span class="badge trustworthy">Model Fairness</span>
              <span class="badge">Knowledge Distillation</span>
              <span class="badge">Vision Language Models</span>


            </td>
          </tr> 
          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/gatha.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              
              <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjuw-zdi4eBAxV0wjgGHX7OBrcQFnoECAsQAw&url=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent%2FCVPR2023W%2FCVFAD%2Fpapers%2FJandial_Gatha_Relational_Loss_for_Enhancing_Text-Based_Style_Transfer_CVPRW_2023_paper.pdf&usg=AOvVaw3UEKegC3CA2Sopr6W4tgXc&opi=89978449">
                <papertitle>Gatha: Relational Loss for enhancing text-based style transfer</papertitle>
              </a>
              <br>
              <u><strong>Surgan Jandial</strong></u>,  &nbsp;
              Shripad Deshmukh,  &nbsp;
              Abhinav Java,  &nbsp;
              Simra Shahid,  &nbsp; Balaji Krishnamurthy <br>
              <br>
        <em><a href="https://sites.google.com/view/cvfad2023/home">6th Workshop on Computer Vision for Fashion, Art, and Design, CVPR 2023 </a> </em> <u><strong><font style="color:red;">(Oral)</font></strong></u>
              <br> <p></p>
              <span class="badge trustworthy">Synthetic Data Generation</span>
              <span class="badge">Vision Language Models</span>

            </td>
          </tr> 

          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/gan_drawio.dms' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              
              <!-- <a href="https://arxiv.org/abs/2205.03859"> -->
                <papertitle>Self-supervised Autoencoder for Correlation-Preserving in Tabular GANs</papertitle>
              <!-- </a> -->
              <br>
              Siddarth Ramesh<sup>*</sup>,  &nbsp;
              <u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp;
              Gauri Gupta<sup>*</sup>,  &nbsp;
              Piyush Gupta,  &nbsp; Balaji Krishnamurthy <br>
              <br>
        <em><a href="https://dmlr.ai">Data-centric Machine Learning Research (DMLR) Workshop, ICML 2023 </a> </em>
              <br> <br>
              <span class="badge trustworthy">Synthetic Data Generation</span>
              <span class="badge">Tabular Data</span>

            </td>
          </tr> 

          <!-- <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/refresh.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td> -->

            <!-- <td style="padding:20px;width:75%;vertical-align:middle">
              
              <a href="https://neuripscreativityworkshop.github.io/2023/papers/ml4cd2023_paper24.pdf">
                <papertitle> Contextual Alchemy: A Framework for Enhanced
                  Readability through Cross-Domain Entity Alignment </papertitle>
              </a>
              <br>
              Simra Shahid,  &nbsp; Nikitha Srikanth,  &nbsp;
              <u><strong>Surgan Jandial</strong></u>,  &nbsp; Balaji Krishnamurthy
              <br> <br>
        <em><a href="https://neuripscreativityworkshop.github.io/2023/">Workshop on Machine Learning for Creativity and Design, Neurips 2023</a> <br>
              <br> </em> <p></p> 
              <span class="badge trustworthy">Applications</span>
              <span class="badge">Large Language Models</span>


            </td> -->
          <!-- </tr>  -->


          <tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/condition_diffusion_cvpr2022w.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>

            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              
              <a href="https://arxiv.org/abs/2205.03859">
                <papertitle>On Conditioning the Input Noise for Controlled Image Generation with Diffusion Models</papertitle>
              </a>
              <br>
              Vedant Singh<sup>*</sup>,  &nbsp;
              <u><strong>Surgan Jandial <sup>*</sup></strong></u>,  &nbsp;
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra</a>,  &nbsp; Siddarth Ramesh,  &nbsp; Balaji Krishnamurthy,  &nbsp;
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian</a>
              <br> <p></p>
        <em><a href="https://ai4cc.net">Workshop on AI for Content Creation, CVPR 2022 </a> </em>
              <br> <p></p>
              <span class="badge trustworthy">Synthetic Data Generation</span>
              <!-- <span class="badge">Diffusion Models</span> -->


              <!-- <p>Regularizing unseen views during optimization enables view synthesis from as few as 3 input images.</p> -->
            </td>
          </tr> 


          <!-- <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/stycon_cvprw21.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/papers/Chawla_Leveraging_Style_and_Content_Features_for_Text_Conditioned_Image_Retrieval_CVPRW_2021_paper.pdf">
                <papertitle>Leveraging Style and Content features for Text Conditioned Image Retrieval</papertitle>
              </a>
              <br>
             <a href="https://www.pranitchawla.com"> Pranit Chawla </a>,  &nbsp; <u><strong>Surgan Jandial</strong></u>,  &nbsp;
             <a href="http://pinkeshbadjatiya.github.io">Pinkesh Badjatiya</a>,  &nbsp; <a href="http://media.mit.edu/people/ayushc/overview/">Ayush Chopra</a>,  &nbsp; Mausoom Sarkar,  &nbsp;
             Balaji Krishnamurthy
              <br> <p></p>
        <em><a href="https://sites.google.com/zalando.de/cvfad2021/home">Workshop on Computer Vision for Fashion, Art and Design, CVPR 2022 </a> </em>
              <br> <p></p>

              <span class="badge trustworthy">Applications</span>
              <span class="badge">Computer Vision</span>
              <span class="badge">Vision Language Models</span>


            </td>
          </tr> -->
					
          <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/advgan.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1908.00706">
                <papertitle>AdvGAN++: Harnessing latent layers for adversary generation</papertitle>
              </a>
              <br>
              <a href="http://puneet2000.github.io">Puneet Mangla<sup>*</sup></a>,  &nbsp;
              <u><u><strong>Surgan Jandial<sup>*</sup></strong></u></u>,  &nbsp;
              Sakshi Varshney<sup>*</sup>,  &nbsp;
              <a href="https://people.iith.ac.in/vineethnb/index.html">Vineeth N Balasubramanian </a>
              <br> <p></p>
              <em><a href="https://neuralarchitects.org">Neural Architect Workshop, ICCV 2019 </a></em>
              <br>
              <p></p> 
              <span class="badge trustworthy">Robustness</span>
              <span class="badge">Computer Vision</span>

            </td>
          </tr>
					
          <tr onmouseout="urf_stop()" onmouseover="urf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mul_warp.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Ayush_Robust_Cloth_Warping_via_Multi-Scale_Patch_Adversarial_Loss_for_Virtual_ICCVW_2019_paper.pdf">
                <papertitle>Robust Cloth Warping via Multi-Scale Patch Adversarial Loss for VirtualTry-On Framework</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>,  &nbsp;
							<u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp;
              <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,  &nbsp; Mayur Hemani, <br>
              Balaji Krishnamurthy
              <br> <p></p>
							<em><a href="https://project.inria.fr/whbu/">Workshop on Human Behaviour Understanding, ICCV 2019</a></em>
              <br>
              <!-- <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Ayush_Robust_Cloth_Warping_via_Multi-Scale_Patch_Adversarial_Loss_for_Virtual_ICCVW_2019_paper.pdf">arXiv</a> -->
              <p></p>
              <span class="badge trustworthy">Applications</span>
              <span class="badge">Computer Vision</span>

              <!-- <p>
								Incorporating lidar and explicitly modeling the sky lets you reconstruct urban environments.</p> -->
            </td>
          </tr> 

	
  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <img src='images/aux_seg_ton_iccv19.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
      </div>

    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Ayush_Powering_Virtual_Try-On_via_Auxiliary_Human_Segmentation_Learning_ICCVW_2019_paper.pdf">
        <papertitle>Powering Virtual Try-On via Auxiliary Human Segmentation Learning</papertitle>
      </a>
      <br>
      <a href="https://scholar.google.co.in/citations?user=gIlnMF8AAAAJ&hl=en">Kumar Ayush<sup>*</sup></a>,  &nbsp;
      <u><strong>Surgan Jandial<sup>*</sup></strong></u>,  &nbsp;
      <a href="https://www.media.mit.edu/people/ayushc/overview/">Ayush Chopra<sup>*</sup></a>,  &nbsp; Balaji Krishnamurthy 
      <br> <p></p>
			<em> <a href="https://sites.google.com/view/cvcreative">Workshop on Computer Vision for Fashion, Art and Design, ICCV 2019 </a> </em>
      <br> 
      <!-- <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Ayush_Powering_Virtual_Try-On_via_Auxiliary_Human_Segmentation_Learning_ICCVW_2019_paper.pdf">arXiv</a> -->
      <p></p>
      <span class="badge trustworthy">Applications</span>
      <span class="badge">Computer Vision</span>

      <!-- <p>
      Dense depth completion techniques applied to freely-available sparse stereo data can improve NeRF reconstructions in low-data regimes.
      </p> -->
    </td>
  </tr>
	
  <tr id="preprint">
  <td style="padding:20px;width:30%;vertical-align:middle">
    <heading>Preprints</heading> 
    <div style="display: flex;">
      <div > (* denotes equal contribution) </div>
    </div>

  </td>
</tr>

<tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()" >
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
        <img src='images/prompt_bias.png' width="250" height="120" style="margin-left: -6%; margin-top: 8%;">
    </div>

  </td>

  <td style="padding:20px;width:75%;vertical-align:middle">
    
    <a href="https://arxiv.org/pdf/2405.10431">
      <papertitle>Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models</papertitle>
    </a>
    <br>
    Shaz Furniturewala<sup>*</sup>, <u><strong>Surgan Jandial<sup>*</sup></strong></u>, Abhinav Java, Pragyan Banerjee, Simra Shahid, Sumit Bhatia, Kokil Jaidka

    <br> <br>
Under review at a Top-Tier ML Conference
    <br> </em> <p></p> 
    <span class="badge trustworthy">Model Fairness</span>
    <span class="badge">Large Language Models</span>
    <!-- <span class="badge">Promp</span> -->

  </td>
</tr> 


<tr onmouseout="regnerf_stop()" onmouseover="regnerf_start()" >
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
        <img src='images/stylrel.png' width="200" height="120" style="margin-left: -8%; margin-top: 8%;">
    </div>

  </td>

  <td style="padding:20px;width:75%;vertical-align:middle">
    
    <a href="data/pdfs/zzwsyqbqxqqgypdcpjxssbhbxxbgchnh.pdf">
      <papertitle>Leveraging style-based relations for text-conditioned style transfer</papertitle>
    </a>
    <br>
    
    <u><strong>Surgan Jandial<sup>*</sup></strong></u>, Silky Singh<sup>*</sup>, Simra Shahid<sup>*</sup>, Abhinav Java, Shripad Deshmukh 
    <br> <br>
Under review at a Top-Tier ML Conference
    <br> </em> <p></p> 
    <span class="badge trustworthy">Synthetic Data Generation</span>
    <span class="badge">Style Transfer</span>
    <span class="badge">Vision Language Models</span>

  </td>
</tr> 

  <tr>
    <td style="padding:20px;vertical-align:middle">
      <heading>Patents</heading>
    </td>
  </tr>  

  <tr>
        </tbody></table>

  <div id="patents">

        <table>
          <tbody>
            <tr>
              <td>
                <ol>

                  <li><span class="badge issues"> Issued</span> <strong> Cloth Warping Using Multi-Scale Patch Adversarial Loss </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <em style="font-size: small;"> Application granted on 06/08/2021. US Patent number 11080817 </em>  </li>
                  <li><span class="badge issues"> Issued </span> <strong> Accurately Generating Virtual Try-On Images Utilizing a Unified Neural Network Framework </strong><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Application granted on 08/03/2021. US Patent number 11030782 </em> </li>
                   <li><span class="badge issues"> Issued </span> <strong> Text-Conditioned Image Search with Transformation, Aggregation, and Composition of Visio-Linguistic Features </strong><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Application granted on 08/08/2023. US Patent number 11720651 </em> </li>
                   <li><span class="badge issues"> Issued </span>  <strong> Model Training with Retrospective Loss </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Application granted on 10/24/2023. US Patent number 11797823  </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Text-Conditioned Image Search Based on Dual-Disentangled Feature Composition </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 1/28/2021 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Regularizing Targets in Model Distillation Utilizing Past State Knowledge of Students </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;">  Filled at the US Patent Office on 8/9/2022 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Diffusion Model Image Generation </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 8/31/2022 </em></li>
                    <li><span class="badge filed">Filed</span> <strong> Systems and Methods for Data Augmentation </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 10/11/2022 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Systems and Methods for Machine Learning Transferability </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 3/3/2023 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Form Structure Similarity Detection </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 3/27/2023 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Personalized Form Error Correction Propagation</strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 4/27/2023 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Knowledge Distillation Using Contextual Semantic Noise </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 2/22/2023 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> Systems and Methods for Generating Synthetic Tabular Data for Machine Learning and Other Applications </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 4/3/2023 </em> </li>
                    <li><span class="badge filed">Filed</span> <strong> One-Shot Document Snippet Search </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  <em style="font-size: small;"> Filled at the US Patent Office on 6/30/2023 </em></li>
                    <li><span class="badge filed">Filed</span> <strong> Generating Alternative Examples for Content </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Filled at the US Patent Office on 11/3/2023 </em>  </li>
                    <li><span class="badge filing">In-Filing</span> <strong> A Novel Method and Apparatus for Text-Guided Style Transfer</strong> <br>  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Internally approved at Adobe Inc. in June 2023 for filing  </em>  </li>
                    <!-- <li><span class="badge filing">In-Filing</span> <strong> A Novel Framework for Bias Aware Distillation using Student Feedback</strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Internally approved at Adobe Inc. in December 2023 for filing </em> </li> -->
                    <li><span class="badge filing">In-Filing</span> <strong> Mask-CLIPstyler: Localized text-based style transfer in images </strong> <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <em style="font-size: small;"> Internally approved at Adobe Inc. in July 2024 for filing </em> </li>


                  </ol>
              </td>
            </tr>

          </tbody>

        </table>
        </div>

        
        <div>


          <table class="academic">
            <tbody>
          <tr>
            <td style="padding:10px;vertical-align:middle">
              <heading class="academic">Academic Service</heading>
            </td>
          </tr>  
              
        <tr>
          <td>

            <ul>
                <li> <strong> Reviewer </strong>: WACV 2020, Neurips 2023 Workshops, WACV 2024, CVPR 2024, KDD 2024, WACV 2025. </li>
                <li> <strong> Program Committee</strong>: AAAI 2025. &nbsp; <strong>Sub-Reviewer</strong>: Neuips 2022, ICCV 2023. </li>
                <li> <strong> Student Volunteer </strong>: ICCV 2019, ICML 2020, KDD 2020, Neurips 2020, ICLR 2020, Recsys 2020.</li>
                <li><strong>Teaching Assistant, IIT Hyderabad:</strong> CS-2323 (Computer Architecture), CS-2410 (Theory of Computation), CS-2420 (Introduction to Complexity Theory).  </li>

            </ul>

          </td>
        </tr>

      </tbody>
          </table>

        </div>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <!-- <td>
            <u><strong>* </strong></u> denotes equal contribution
            </td> -->
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 <a href="https://jonbarron.info"> this </a> made my life easy.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
  
</body>

</html>
